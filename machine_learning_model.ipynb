{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv, BatchNorm, Linear\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from src.utils.dataset import get_full_transactions_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Using Torch version {torch.__version__}\")\n",
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\") \n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"Name of current CUDA device:{torch.cuda.get_device_name(cuda_id)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set load\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_full_transactions_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_columns = [\"receiving_currency\", \"payment_currency\", \"payment_format\"]\n",
    "label_encoder = LabelEncoder()\n",
    "for column in label_encoder_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "df['timestamp'] = df['timestamp'].apply(lambda x: x.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=\"sender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df[['amount_received', 'amount_paid', 'timestamp']] = scaler.fit_transform(df[['amount_received', 'amount_paid', 'timestamp']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_account_ids = set(df['sender']).union(set(df['receiver']))\n",
    "nodes_df = pd.DataFrame({'account': list(all_account_ids)})\n",
    "nodes_df = nodes_df.sort_values(by=\"account\").reset_index(drop=True)\n",
    "laundering_df = df[df[\"is_laundering\"] == 1]\n",
    "laundering_accounts = set(laundering_df['sender']).union(set(laundering_df['receiver']))\n",
    "nodes_df[\"is_laundering\"] = nodes_df.account.apply(lambda account_id: 1 if account_id in laundering_accounts else 0)\n",
    "nodes_df = nodes_df.sort_values(by=\"account\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df[\"transactions_sent\"] = nodes_df['account'].map(df.groupby('sender').size()).fillna(0)\n",
    "nodes_df['transactions_received'] = nodes_df['account'].map(df.groupby('receiver').size()).fillna(0)\n",
    "nodes_df['unique_currencies_sent'] = nodes_df['account'].map(df.groupby('sender')['payment_currency'].nunique()).fillna(0)\n",
    "nodes_df['unique_currencies_received'] = nodes_df['account'].map(df.groupby('receiver')['payment_currency'].nunique()).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currencies = set(set(df['payment_currency']).union(set(df['receiving_currency'])))\n",
    "for currency in currencies:\n",
    "    nodes_df[f'average_paid_{currency}'] = nodes_df['account'].map(\n",
    "        df[df['payment_currency'] == currency].groupby('sender')['amount_paid'].mean()\n",
    "    ).fillna(0)\n",
    "    \n",
    "    nodes_df[f'total_received_{currency}'] = nodes_df['account'].map(\n",
    "        df[df['receiving_currency'] == currency].groupby('receiver')['amount_received'].mean()\n",
    "    ).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labels = torch.from_numpy(nodes_df[\"is_laundering\"].values).to(torch.float)\n",
    "nodes_df = nodes_df.drop([\"account\", \"is_laundering\"], axis=1)\n",
    "node_features = torch.from_numpy(nodes_df.values).to(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_to_index = {acc: idx for idx, acc in enumerate(all_account_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df['sender'] = edges_df['sender'].map(account_to_index)\n",
    "edges_df['receiver'] = edges_df['receiver'].map(account_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.stack([torch.from_numpy(edges_df['sender'].values), torch.from_numpy(edges_df['receiver'].values)], dim=0)\n",
    "edge_attr = torch.from_numpy(edges_df.drop(columns=[\"sender\", \"receiver\", \"is_laundering\"]).values).to(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr, y=node_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.bincount(graph_data.y.to(torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_fraudulent_nodes(data, fraud_label=1, removal_percentage=0.5):\n",
    "    non_fraud_nodes = torch.where(data.y != fraud_label)[0]\n",
    "    num_to_remove = int(len(non_fraud_nodes) * removal_percentage)\n",
    "    \n",
    "    nodes_to_remove = np.random.choice(non_fraud_nodes.numpy(), num_to_remove, replace=False)\n",
    "    nodes_to_remove = torch.tensor(nodes_to_remove, dtype=torch.long)\n",
    "    \n",
    "    mask = torch.ones(data.num_nodes, dtype=torch.bool)\n",
    "    mask[nodes_to_remove] = False  \n",
    "    remaining_nodes = torch.nonzero(mask, as_tuple=True)[0]  \n",
    "\n",
    "    node_map = {old_idx.item(): new_idx for new_idx, old_idx in enumerate(remaining_nodes)}\n",
    "    mask_edges = mask[data.edge_index[0]] & mask[data.edge_index[1]]\n",
    "    new_edge_index = data.edge_index[:, mask_edges]\n",
    "\n",
    "    new_edge_index = torch.tensor([[node_map[idx.item()] for idx in row] for row in new_edge_index], dtype=torch.long)\n",
    "\n",
    "    if data.edge_attr is not None:\n",
    "        new_edge_attr = data.edge_attr[mask_edges]\n",
    "    else:\n",
    "        new_edge_attr = None\n",
    "\n",
    "    new_data = data.__class__(\n",
    "        x=data.x[remaining_nodes],  \n",
    "        edge_index=new_edge_index,  \n",
    "        edge_attr=new_edge_attr,  \n",
    "        y=data.y[remaining_nodes]\n",
    "    )\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removal_percentage = 0.25\n",
    "graph_data = remove_non_fraudulent_nodes(graph_data, fraud_label=1, removal_percentage=removal_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.bincount(graph_data.y.to(torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATModel(torch.nn.Module):\n",
    "    def __init__(self, in_feats, hidden_dim, out_feats, heads):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(in_feats, hidden_dim, heads, dropout=0.2)\n",
    "        self.conv2 = GATConv(hidden_dim * heads, hidden_dim, heads=1, concat=False, dropout=0.2)\n",
    "        self.conv3 = GATConv(hidden_dim, int(hidden_dim/2), heads=1, concat=False, dropout=0.2)\n",
    "\n",
    "        self.bn1 = BatchNorm(hidden_dim * heads)\n",
    "        self.bn2 = BatchNorm(hidden_dim)\n",
    "        self.bn3 = BatchNorm(int(hidden_dim/2))\n",
    "\n",
    "        self.lin = Linear(int(hidden_dim/2), out_feats)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.bn1(F.leaky_relu(self.conv1(x, edge_index, edge_attr)))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.bn2(F.leaky_relu(self.conv2(x, edge_index, edge_attr)))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.bn3(F.leaky_relu(self.conv3(x, edge_index, edge_attr)))\n",
    "\n",
    "        x = self.lin(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"lr\": [1e-4],\n",
    "    \"batch_size\": [1024],\n",
    "    \"num_neighbors\": [[64,64], [256,256]],\n",
    "    \"hidden_dim\": [16, 32, 64],\n",
    "    \"heads\": [16, 32]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_combinations = len(list(ParameterGrid(param_grid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = T.RandomNodeSplit(split='train_rest', num_val=0.1, num_test=0)\n",
    "graph_data = train_test_split(graph_data).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.array([0, 1]), y=graph_data.y.cpu().numpy())\n",
    "pos_weight = torch.tensor([class_weights[1]], dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loader(graph_data, mask, params):\n",
    "    return NeighborLoader(\n",
    "        graph_data,\n",
    "        num_neighbors=params[\"num_neighbors\"],\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        input_nodes=mask,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = None\n",
    "best_auc = 0\n",
    "param_combination = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"\\nTesting parameters ({param_combination}/{num_combinations}): {params}\")\n",
    "    param_combination += 1\n",
    "    print(f\"Best AUC until now: {best_auc:.2f}\")\n",
    "    \n",
    "    train_loader = create_loader(graph_data, graph_data.train_mask, params)\n",
    "    test_loader = create_loader(graph_data, graph_data.val_mask, params)\n",
    "\n",
    "    model = GATModel(\n",
    "        in_feats=graph_data.num_features,\n",
    "        hidden_dim=params[\"hidden_dim\"],\n",
    "        out_feats=1,\n",
    "        heads=params[\"heads\"]\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    num_epochs = 100\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        running_loss = 0.0 \n",
    "        \n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "            loss = criterion(out, batch.y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        epoch_duration = time.time() - start_time\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == num_epochs:\n",
    "            model.eval()\n",
    "            y_true, y_pred_probs = [], []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in test_loader:\n",
    "                    out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "                    y_true.extend(batch.y.cpu().numpy())\n",
    "                    y_pred_probs.extend(out.cpu().numpy())\n",
    "\n",
    "            y_pred_probs = np.array(y_pred_probs).flatten()\n",
    "            auc_score = roc_auc_score(y_true, y_pred_probs)\n",
    "\n",
    "            if auc_score > best_auc:\n",
    "                best_params = params\n",
    "                best_auc = auc_score\n",
    "            print(f\"Epoch {epoch}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | AUC: {auc_score:.4f} | Time: {epoch_duration:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'batch_size': 4096, 'heads': 16, 'hidden_dim': 16, 'lr': 0.0001, 'num_neighbors': [64, 64]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred_probs):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='grey', linestyle='--')  # Linha aleatória\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
    "    plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
    "    plt.title('Curva ROC')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_true, y_pred_probs = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        y_true.extend(batch.y.cpu().numpy())\n",
    "        y_pred_probs.extend(out.cpu().numpy())\n",
    "\n",
    "y_pred_probs = np.array(y_pred_probs).flatten()\n",
    "#y_pred = (y_pred_probs >= 0.1).astype(int)  # Converter para 0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(y_true, y_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
