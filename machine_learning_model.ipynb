{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 11:29:22.979 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-03-06 11:29:22.989 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-03-06 11:29:22.989 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv, BatchNorm, Linear\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from src.utils.dataset import get_full_transactions_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Torch version 2.5.1+cu124\n",
      "Is CUDA supported by this system? True\n",
      "CUDA version: 12.4\n",
      "Name of current CUDA device:NVIDIA GeForce RTX 2060\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using Torch version {torch.__version__}\")\n",
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\") \n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"Name of current CUDA device:{torch.cuda.get_device_name(cuda_id)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set load\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 11:29:23.015 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-03-06 11:29:23.016 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-06 11:29:23.404 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\ferna\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-03-06 11:29:23.409 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-06 11:29:23.409 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-06 11:29:23.911 Thread 'Thread-5': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-06 11:29:23.911 Thread 'Thread-5': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-06 11:29:31.479 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-06 11:29:31.479 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "df = get_full_transactions_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_transactions_df = df[df[\"is_laundering\"] == 1]\n",
    "non_fraud_transactions_df = df[df[\"is_laundering\"] == 0].sample(int(3e6))\n",
    "df = pd.concat([fraud_transactions_df, non_fraud_transactions_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_columns = [\"receiving_currency\", \"payment_currency\", \"payment_format\"]\n",
    "label_encoder = LabelEncoder()\n",
    "for column in label_encoder_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "df['timestamp'] = df['timestamp'].apply(lambda x: x.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=\"sender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df[['amount_received', 'amount_paid', 'timestamp']] = scaler.fit_transform(df[['amount_received', 'amount_paid', 'timestamp']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sender</th>\n",
       "      <th>receiver</th>\n",
       "      <th>amount_received</th>\n",
       "      <th>receiving_currency</th>\n",
       "      <th>amount_paid</th>\n",
       "      <th>payment_currency</th>\n",
       "      <th>payment_format</th>\n",
       "      <th>is_laundering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2570346</th>\n",
       "      <td>0.088897</td>\n",
       "      <td>10057_803A115E0</td>\n",
       "      <td>29467_803E020C0</td>\n",
       "      <td>-0.005278</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824238</th>\n",
       "      <td>-1.177713</td>\n",
       "      <td>10057_803A115E0</td>\n",
       "      <td>29467_803E020C0</td>\n",
       "      <td>-0.005378</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.004658</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918768</th>\n",
       "      <td>0.979771</td>\n",
       "      <td>10057_803A115E0</td>\n",
       "      <td>29467_803E020C0</td>\n",
       "      <td>-0.005278</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541410</th>\n",
       "      <td>-0.883571</td>\n",
       "      <td>10057_803A115E0</td>\n",
       "      <td>29467_803E020C0</td>\n",
       "      <td>-0.005278</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3437164</th>\n",
       "      <td>0.659839</td>\n",
       "      <td>10057_803A115E0</td>\n",
       "      <td>29467_803E020C0</td>\n",
       "      <td>-0.005378</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.004658</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp           sender         receiver  amount_received  \\\n",
       "2570346   0.088897  10057_803A115E0  29467_803E020C0        -0.005278   \n",
       "824238   -1.177713  10057_803A115E0  29467_803E020C0        -0.005378   \n",
       "3918768   0.979771  10057_803A115E0  29467_803E020C0        -0.005278   \n",
       "1541410  -0.883571  10057_803A115E0  29467_803E020C0        -0.005278   \n",
       "3437164   0.659839  10057_803A115E0  29467_803E020C0        -0.005378   \n",
       "\n",
       "         receiving_currency  amount_paid  payment_currency  payment_format  \\\n",
       "2570346                  13    -0.004535                13               3   \n",
       "824238                   13    -0.004658                13               4   \n",
       "3918768                  13    -0.004535                13               3   \n",
       "1541410                  13    -0.004535                13               3   \n",
       "3437164                  13    -0.004658                13               4   \n",
       "\n",
       "         is_laundering  \n",
       "2570346              0  \n",
       "824238               0  \n",
       "3918768              0  \n",
       "1541410              0  \n",
       "3437164              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_account_ids = set(df['sender']).union(set(df['receiver']))\n",
    "nodes_df = pd.DataFrame({'account': list(all_account_ids)})\n",
    "nodes_df = nodes_df.sort_values(by=\"account\").reset_index(drop=True)\n",
    "laundering_df = df[df[\"is_laundering\"] == 1]\n",
    "laundering_accounts = set(laundering_df['sender']).union(set(laundering_df['receiver']))\n",
    "nodes_df[\"is_laundering\"] = nodes_df.account.apply(lambda account_id: 1 if account_id in laundering_accounts else 0)\n",
    "nodes_df = nodes_df.sort_values(by=\"account\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df[\"transactions_sent\"] = nodes_df['account'].map(df.groupby('sender').size()).fillna(0)\n",
    "nodes_df['transactions_received'] = nodes_df['account'].map(df.groupby('receiver').size()).fillna(0)\n",
    "nodes_df['unique_currencies_sent'] = nodes_df['account'].map(df.groupby('sender')['payment_currency'].nunique()).fillna(0)\n",
    "nodes_df['unique_currencies_received'] = nodes_df['account'].map(df.groupby('receiver')['payment_currency'].nunique()).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "currencies = set(set(df['payment_currency']).union(set(df['receiving_currency'])))\n",
    "for currency in currencies:\n",
    "    nodes_df[f'average_paid_{currency}'] = nodes_df['account'].map(\n",
    "        df[df['payment_currency'] == currency].groupby('sender')['amount_paid'].mean()\n",
    "    ).fillna(0)\n",
    "    \n",
    "    nodes_df[f'total_received_{currency}'] = nodes_df['account'].map(\n",
    "        df[df['receiving_currency'] == currency].groupby('receiver')['amount_received'].mean()\n",
    "    ).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labels = torch.from_numpy(nodes_df[\"is_laundering\"].values).to(torch.float)\n",
    "nodes_df = nodes_df.drop([\"account\", \"is_laundering\"], axis=1)\n",
    "node_features = torch.from_numpy(nodes_df.values).to(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_to_index = {acc: idx for idx, acc in enumerate(all_account_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df['sender'] = edges_df['sender'].map(account_to_index)\n",
    "edges_df['receiver'] = edges_df['receiver'].map(account_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sender</th>\n",
       "      <th>receiver</th>\n",
       "      <th>amount_received</th>\n",
       "      <th>receiving_currency</th>\n",
       "      <th>amount_paid</th>\n",
       "      <th>payment_currency</th>\n",
       "      <th>payment_format</th>\n",
       "      <th>is_laundering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2570346</th>\n",
       "      <td>0.088897</td>\n",
       "      <td>192863</td>\n",
       "      <td>1082</td>\n",
       "      <td>-0.005278</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824238</th>\n",
       "      <td>-1.177713</td>\n",
       "      <td>192863</td>\n",
       "      <td>1082</td>\n",
       "      <td>-0.005378</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.004658</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918768</th>\n",
       "      <td>0.979771</td>\n",
       "      <td>192863</td>\n",
       "      <td>1082</td>\n",
       "      <td>-0.005278</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541410</th>\n",
       "      <td>-0.883571</td>\n",
       "      <td>192863</td>\n",
       "      <td>1082</td>\n",
       "      <td>-0.005278</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3437164</th>\n",
       "      <td>0.659839</td>\n",
       "      <td>192863</td>\n",
       "      <td>1082</td>\n",
       "      <td>-0.005378</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.004658</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp  sender  receiver  amount_received  receiving_currency  \\\n",
       "2570346   0.088897  192863      1082        -0.005278                  13   \n",
       "824238   -1.177713  192863      1082        -0.005378                  13   \n",
       "3918768   0.979771  192863      1082        -0.005278                  13   \n",
       "1541410  -0.883571  192863      1082        -0.005278                  13   \n",
       "3437164   0.659839  192863      1082        -0.005378                  13   \n",
       "\n",
       "         amount_paid  payment_currency  payment_format  is_laundering  \n",
       "2570346    -0.004535                13               3              0  \n",
       "824238     -0.004658                13               4              0  \n",
       "3918768    -0.004535                13               3              0  \n",
       "1541410    -0.004535                13               3              0  \n",
       "3437164    -0.004658                13               4              0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.stack([torch.from_numpy(edges_df['sender'].values), torch.from_numpy(edges_df['receiver'].values)], dim=0)\n",
    "edge_attr = torch.from_numpy(edges_df.drop(columns=[\"sender\", \"receiver\", \"is_laundering\"]).values).to(torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr, y=node_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[456288, 34], edge_index=[2, 3005177], edge_attr=[3005177, 6], y=[456288])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.bincount(graph_data.y.to(torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def remove_non_fraudulent_nodes(data, fraud_label=1, removal_percentage=0.5):\n",
    "    non_fraud_nodes = torch.where(data.y != fraud_label)[0]\n",
    "    num_to_remove = int(len(non_fraud_nodes) * removal_percentage)\n",
    "    \n",
    "    nodes_to_remove = np.random.choice(non_fraud_nodes.numpy(), num_to_remove, replace=False)\n",
    "    nodes_to_remove = torch.tensor(nodes_to_remove, dtype=torch.long)\n",
    "    \n",
    "    mask = torch.ones(data.num_nodes, dtype=torch.bool)\n",
    "    mask[nodes_to_remove] = False  \n",
    "    remaining_nodes = torch.nonzero(mask, as_tuple=True)[0]  \n",
    "\n",
    "    node_map = {old_idx.item(): new_idx for new_idx, old_idx in enumerate(remaining_nodes)}\n",
    "    mask_edges = mask[data.edge_index[0]] & mask[data.edge_index[1]]\n",
    "    new_edge_index = data.edge_index[:, mask_edges]\n",
    "\n",
    "    new_edge_index = torch.tensor([[node_map[idx.item()] for idx in row] for row in new_edge_index], dtype=torch.long)\n",
    "\n",
    "    if data.edge_attr is not None:\n",
    "        new_edge_attr = data.edge_attr[mask_edges]\n",
    "    else:\n",
    "        new_edge_attr = None\n",
    "\n",
    "    new_data = data.__class__(\n",
    "        x=data.x[remaining_nodes],  \n",
    "        edge_index=new_edge_index,  \n",
    "        edge_attr=new_edge_attr,  \n",
    "        y=data.y[remaining_nodes]\n",
    "    )\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removal_percentage = 0.25\n",
    "graph_data = remove_non_fraudulent_nodes(graph_data, fraud_label=1, removal_percentage=removal_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.bincount(graph_data.y.to(torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATModel(torch.nn.Module):\n",
    "    def __init__(self, in_feats, hidden_dim, out_feats, heads):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(in_feats, hidden_dim, heads, dropout=0.2)\n",
    "        self.conv2 = GATConv(hidden_dim * heads, hidden_dim, heads=1, concat=False, dropout=0.2)\n",
    "        self.conv3 = GATConv(hidden_dim, int(hidden_dim/2), heads=1, concat=False, dropout=0.2)\n",
    "\n",
    "        self.bn1 = BatchNorm(hidden_dim * heads)\n",
    "        self.bn2 = BatchNorm(hidden_dim)\n",
    "        self.bn3 = BatchNorm(int(hidden_dim/2))\n",
    "\n",
    "        self.lin = Linear(int(hidden_dim/2), out_feats)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.bn1(F.leaky_relu(self.conv1(x, edge_index, edge_attr)))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.bn2(F.leaky_relu(self.conv2(x, edge_index, edge_attr)))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.bn3(F.leaky_relu(self.conv3(x, edge_index, edge_attr)))\n",
    "\n",
    "        x = self.lin(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"lr\": [1e-4],\n",
    "    \"batch_size\": [1024],\n",
    "    \"num_neighbors\": [[64,64], [256,256]],\n",
    "    \"hidden_dim\": [16, 32, 64],\n",
    "    \"heads\": [16, 32]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_combinations = len(list(ParameterGrid(param_grid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = T.RandomNodeSplit(split='train_rest', num_val=0.1, num_test=0)\n",
    "graph_data = train_test_split(graph_data).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.array([0, 1]), y=graph_data.y.cpu().numpy())\n",
    "pos_weight = torch.tensor([class_weights[1]], dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loader(graph_data, mask, params):\n",
    "    return NeighborLoader(\n",
    "        graph_data,\n",
    "        num_neighbors=params[\"num_neighbors\"],\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        input_nodes=mask,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = None\n",
    "best_auc = 0\n",
    "param_combination = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing parameters (1/12): {'batch_size': 1024, 'heads': 16, 'hidden_dim': 16, 'lr': 0.0001, 'num_neighbors': [64, 64]}\n",
      "Best AUC until now: 0.00\n",
      "Epoch 10/100 | Train Loss: 1.0585 | AUC: 0.6156 | Time: 9.96s\n",
      "Epoch 20/100 | Train Loss: 1.0275 | AUC: 0.6249 | Time: 11.77s\n",
      "Epoch 30/100 | Train Loss: 1.0241 | AUC: 0.6597 | Time: 10.89s\n",
      "Epoch 40/100 | Train Loss: 1.0239 | AUC: 0.6589 | Time: 10.75s\n",
      "Epoch 50/100 | Train Loss: 1.0233 | AUC: 0.6588 | Time: 10.81s\n",
      "Epoch 60/100 | Train Loss: 1.0233 | AUC: 0.6561 | Time: 11.00s\n",
      "Epoch 70/100 | Train Loss: 1.0231 | AUC: 0.6573 | Time: 11.07s\n",
      "Epoch 80/100 | Train Loss: 1.0231 | AUC: 0.6596 | Time: 10.40s\n",
      "Epoch 90/100 | Train Loss: 1.0224 | AUC: 0.6577 | Time: 9.13s\n",
      "Epoch 100/100 | Train Loss: 1.0222 | AUC: 0.6599 | Time: 9.38s\n",
      "\n",
      "Testing parameters (2/12): {'batch_size': 1024, 'heads': 16, 'hidden_dim': 16, 'lr': 0.0001, 'num_neighbors': [256, 256]}\n",
      "Best AUC until now: 0.66\n",
      "Epoch 10/100 | Train Loss: 1.0612 | AUC: 0.6715 | Time: 9.15s\n",
      "Epoch 20/100 | Train Loss: 1.0282 | AUC: 0.6765 | Time: 9.58s\n",
      "Epoch 30/100 | Train Loss: 1.0248 | AUC: 0.6758 | Time: 9.20s\n",
      "Epoch 40/100 | Train Loss: 1.0249 | AUC: 0.6665 | Time: 9.35s\n",
      "Epoch 50/100 | Train Loss: 1.0254 | AUC: 0.6624 | Time: 9.15s\n",
      "Epoch 60/100 | Train Loss: 1.0242 | AUC: 0.6548 | Time: 10.11s\n",
      "Epoch 70/100 | Train Loss: 1.0254 | AUC: 0.6665 | Time: 9.25s\n",
      "Epoch 80/100 | Train Loss: 1.0235 | AUC: 0.6677 | Time: 9.22s\n",
      "Epoch 90/100 | Train Loss: 1.0239 | AUC: 0.6760 | Time: 9.23s\n",
      "Epoch 100/100 | Train Loss: 1.0238 | AUC: 0.6767 | Time: 9.37s\n",
      "\n",
      "Testing parameters (3/12): {'batch_size': 1024, 'heads': 16, 'hidden_dim': 32, 'lr': 0.0001, 'num_neighbors': [64, 64]}\n",
      "Best AUC until now: 0.68\n",
      "Epoch 10/100 | Train Loss: 1.0430 | AUC: 0.6689 | Time: 9.52s\n",
      "Epoch 20/100 | Train Loss: 1.0245 | AUC: 0.6660 | Time: 11.19s\n",
      "Epoch 30/100 | Train Loss: 1.0234 | AUC: 0.6660 | Time: 10.27s\n",
      "Epoch 40/100 | Train Loss: 1.0225 | AUC: 0.6431 | Time: 10.29s\n",
      "Epoch 50/100 | Train Loss: 1.0220 | AUC: 0.6665 | Time: 10.07s\n",
      "Epoch 60/100 | Train Loss: 1.0218 | AUC: 0.6625 | Time: 10.13s\n",
      "Epoch 70/100 | Train Loss: 1.0220 | AUC: 0.6652 | Time: 9.64s\n",
      "Epoch 80/100 | Train Loss: 1.0221 | AUC: 0.6652 | Time: 9.41s\n",
      "Epoch 90/100 | Train Loss: 1.0220 | AUC: 0.6635 | Time: 9.60s\n",
      "Epoch 100/100 | Train Loss: 1.0223 | AUC: 0.6721 | Time: 10.29s\n",
      "\n",
      "Testing parameters (4/12): {'batch_size': 1024, 'heads': 16, 'hidden_dim': 32, 'lr': 0.0001, 'num_neighbors': [256, 256]}\n",
      "Best AUC until now: 0.68\n",
      "Epoch 10/100 | Train Loss: 1.0497 | AUC: 0.6751 | Time: 10.41s\n",
      "Epoch 20/100 | Train Loss: 1.0256 | AUC: 0.6805 | Time: 10.47s\n",
      "Epoch 30/100 | Train Loss: 1.0250 | AUC: 0.6731 | Time: 10.44s\n",
      "Epoch 40/100 | Train Loss: 1.0236 | AUC: 0.6781 | Time: 10.46s\n",
      "Epoch 50/100 | Train Loss: 1.0230 | AUC: 0.6676 | Time: 10.43s\n",
      "Epoch 60/100 | Train Loss: 1.0229 | AUC: 0.6656 | Time: 9.68s\n",
      "Epoch 70/100 | Train Loss: 1.0238 | AUC: 0.6632 | Time: 9.57s\n",
      "Epoch 80/100 | Train Loss: 1.0232 | AUC: 0.6483 | Time: 9.72s\n",
      "Epoch 90/100 | Train Loss: 1.0237 | AUC: 0.6501 | Time: 10.41s\n",
      "Epoch 100/100 | Train Loss: 1.0232 | AUC: 0.6618 | Time: 10.39s\n",
      "\n",
      "Testing parameters (5/12): {'batch_size': 1024, 'heads': 16, 'hidden_dim': 64, 'lr': 0.0001, 'num_neighbors': [64, 64]}\n",
      "Best AUC until now: 0.68\n",
      "Epoch 10/100 | Train Loss: 1.0424 | AUC: 0.5365 | Time: 12.32s\n",
      "Epoch 20/100 | Train Loss: 1.0252 | AUC: 0.6312 | Time: 12.14s\n",
      "Epoch 30/100 | Train Loss: 1.0245 | AUC: 0.6626 | Time: 12.29s\n",
      "Epoch 40/100 | Train Loss: 1.0231 | AUC: 0.6628 | Time: 870.91s\n",
      "Epoch 50/100 | Train Loss: 1.0238 | AUC: 0.6750 | Time: 14.41s\n",
      "Epoch 60/100 | Train Loss: 1.0225 | AUC: 0.6532 | Time: 13.47s\n",
      "Epoch 70/100 | Train Loss: 1.0234 | AUC: 0.6658 | Time: 13.52s\n",
      "Epoch 80/100 | Train Loss: 1.0222 | AUC: 0.6660 | Time: 13.65s\n",
      "Epoch 90/100 | Train Loss: 1.0225 | AUC: 0.6710 | Time: 14.41s\n",
      "Epoch 100/100 | Train Loss: 1.0220 | AUC: 0.6752 | Time: 13.70s\n",
      "\n",
      "Testing parameters (6/12): {'batch_size': 1024, 'heads': 16, 'hidden_dim': 64, 'lr': 0.0001, 'num_neighbors': [256, 256]}\n",
      "Best AUC until now: 0.68\n",
      "Epoch 10/100 | Train Loss: 1.0421 | AUC: 0.5954 | Time: 13.98s\n",
      "Epoch 20/100 | Train Loss: 1.0252 | AUC: 0.6244 | Time: 14.34s\n",
      "Epoch 30/100 | Train Loss: 1.0239 | AUC: 0.6111 | Time: 13.85s\n",
      "Epoch 40/100 | Train Loss: 1.0229 | AUC: 0.5865 | Time: 14.05s\n",
      "Epoch 50/100 | Train Loss: 1.0227 | AUC: 0.6244 | Time: 13.57s\n",
      "Epoch 60/100 | Train Loss: 1.0223 | AUC: 0.6245 | Time: 13.56s\n",
      "Epoch 70/100 | Train Loss: 1.0225 | AUC: 0.6551 | Time: 15.16s\n",
      "Epoch 80/100 | Train Loss: 1.0217 | AUC: 0.6427 | Time: 15.39s\n",
      "Epoch 90/100 | Train Loss: 1.0220 | AUC: 0.6371 | Time: 14.27s\n",
      "Epoch 100/100 | Train Loss: 1.0221 | AUC: 0.6314 | Time: 14.85s\n",
      "\n",
      "Testing parameters (7/12): {'batch_size': 1024, 'heads': 32, 'hidden_dim': 16, 'lr': 0.0001, 'num_neighbors': [64, 64]}\n",
      "Best AUC until now: 0.68\n",
      "Epoch 10/100 | Train Loss: 1.0603 | AUC: 0.6648 | Time: 12.30s\n",
      "Epoch 20/100 | Train Loss: 1.0265 | AUC: 0.6618 | Time: 12.34s\n",
      "Epoch 30/100 | Train Loss: 1.0237 | AUC: 0.6614 | Time: 11.71s\n",
      "Epoch 40/100 | Train Loss: 1.0236 | AUC: 0.6720 | Time: 12.65s\n",
      "Epoch 50/100 | Train Loss: 1.0229 | AUC: 0.6672 | Time: 13.18s\n",
      "Epoch 60/100 | Train Loss: 1.0229 | AUC: 0.6569 | Time: 12.35s\n",
      "Epoch 70/100 | Train Loss: 1.0228 | AUC: 0.6565 | Time: 12.47s\n",
      "Epoch 80/100 | Train Loss: 1.0230 | AUC: 0.6483 | Time: 12.45s\n",
      "Epoch 90/100 | Train Loss: 1.0226 | AUC: 0.6665 | Time: 10.80s\n",
      "Epoch 100/100 | Train Loss: 1.0233 | AUC: 0.6562 | Time: 10.85s\n",
      "\n",
      "Testing parameters (8/12): {'batch_size': 1024, 'heads': 32, 'hidden_dim': 16, 'lr': 0.0001, 'num_neighbors': [256, 256]}\n",
      "Best AUC until now: 0.68\n",
      "Epoch 10/100 | Train Loss: 1.0551 | AUC: 0.4759 | Time: 11.33s\n",
      "Epoch 20/100 | Train Loss: 1.0284 | AUC: 0.5715 | Time: 11.38s\n",
      "Epoch 30/100 | Train Loss: 1.0248 | AUC: 0.5873 | Time: 11.27s\n",
      "Epoch 40/100 | Train Loss: 1.0250 | AUC: 0.6586 | Time: 11.21s\n",
      "Epoch 50/100 | Train Loss: 1.0251 | AUC: 0.6593 | Time: 11.25s\n",
      "Epoch 60/100 | Train Loss: 1.0248 | AUC: 0.6736 | Time: 12.14s\n",
      "Epoch 70/100 | Train Loss: 1.0238 | AUC: 0.6696 | Time: 11.98s\n",
      "Epoch 80/100 | Train Loss: 1.0231 | AUC: 0.6524 | Time: 11.83s\n",
      "Epoch 90/100 | Train Loss: 1.0236 | AUC: 0.6476 | Time: 12.11s\n",
      "Epoch 100/100 | Train Loss: 1.0235 | AUC: 0.6581 | Time: 10.20s\n",
      "\n",
      "Testing parameters (9/12): {'batch_size': 1024, 'heads': 32, 'hidden_dim': 32, 'lr': 0.0001, 'num_neighbors': [64, 64]}\n",
      "Best AUC until now: 0.68\n",
      "Epoch 10/100 | Train Loss: 1.0466 | AUC: 0.6682 | Time: 13.60s\n",
      "Epoch 20/100 | Train Loss: 1.0246 | AUC: 0.6573 | Time: 13.97s\n",
      "Epoch 30/100 | Train Loss: 1.0238 | AUC: 0.6682 | Time: 14.68s\n",
      "Epoch 40/100 | Train Loss: 1.0237 | AUC: 0.6464 | Time: 14.14s\n",
      "Epoch 50/100 | Train Loss: 1.0235 | AUC: 0.6373 | Time: 14.33s\n",
      "Epoch 60/100 | Train Loss: 1.0233 | AUC: 0.6532 | Time: 14.79s\n",
      "Epoch 70/100 | Train Loss: 1.0230 | AUC: 0.6596 | Time: 15.00s\n",
      "Epoch 80/100 | Train Loss: 1.0225 | AUC: 0.6613 | Time: 14.21s\n",
      "Epoch 90/100 | Train Loss: 1.0231 | AUC: 0.6545 | Time: 14.84s\n",
      "Epoch 100/100 | Train Loss: 1.0224 | AUC: 0.6581 | Time: 12.13s\n",
      "\n",
      "Testing parameters (10/12): {'batch_size': 1024, 'heads': 32, 'hidden_dim': 32, 'lr': 0.0001, 'num_neighbors': [256, 256]}\n",
      "Best AUC until now: 0.68\n",
      "Epoch 10/100 | Train Loss: 1.0470 | AUC: 0.6857 | Time: 13.35s\n",
      "Epoch 20/100 | Train Loss: 1.0253 | AUC: 0.6925 | Time: 13.16s\n",
      "Epoch 30/100 | Train Loss: 1.0232 | AUC: 0.6683 | Time: 12.77s\n",
      "Epoch 40/100 | Train Loss: 1.0248 | AUC: 0.6550 | Time: 12.73s\n",
      "Epoch 50/100 | Train Loss: 1.0233 | AUC: 0.6721 | Time: 13.31s\n",
      "Epoch 60/100 | Train Loss: 1.0233 | AUC: 0.6532 | Time: 13.04s\n",
      "Epoch 70/100 | Train Loss: 1.0222 | AUC: 0.6579 | Time: 12.82s\n",
      "Epoch 80/100 | Train Loss: 1.0231 | AUC: 0.6505 | Time: 12.54s\n",
      "Epoch 90/100 | Train Loss: 1.0224 | AUC: 0.6516 | Time: 13.57s\n",
      "Epoch 100/100 | Train Loss: 1.0221 | AUC: 0.6541 | Time: 12.73s\n",
      "\n",
      "Testing parameters (11/12): {'batch_size': 1024, 'heads': 32, 'hidden_dim': 64, 'lr': 0.0001, 'num_neighbors': [64, 64]}\n",
      "Best AUC until now: 0.69\n",
      "Epoch 10/100 | Train Loss: 1.0318 | AUC: 0.6539 | Time: 25.64s\n",
      "Epoch 20/100 | Train Loss: 1.0234 | AUC: 0.6388 | Time: 26.89s\n",
      "Epoch 30/100 | Train Loss: 1.0233 | AUC: 0.6616 | Time: 26.72s\n",
      "Epoch 40/100 | Train Loss: 1.0231 | AUC: 0.5670 | Time: 26.88s\n",
      "Epoch 50/100 | Train Loss: 1.0221 | AUC: 0.5887 | Time: 30.07s\n",
      "Epoch 60/100 | Train Loss: 1.0220 | AUC: 0.5456 | Time: 29.43s\n"
     ]
    }
   ],
   "source": [
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"\\nTesting parameters ({param_combination}/{num_combinations}): {params}\")\n",
    "    param_combination += 1\n",
    "    print(f\"Best AUC until now: {best_auc:.2f}\")\n",
    "    \n",
    "    train_loader = create_loader(graph_data, graph_data.train_mask, params)\n",
    "    test_loader = create_loader(graph_data, graph_data.val_mask, params)\n",
    "\n",
    "    model = GATModel(\n",
    "        in_feats=graph_data.num_features,\n",
    "        hidden_dim=params[\"hidden_dim\"],\n",
    "        out_feats=1,\n",
    "        heads=params[\"heads\"]\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    num_epochs = 100\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        running_loss = 0.0 \n",
    "        \n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "            loss = criterion(out, batch.y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        epoch_duration = time.time() - start_time\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == num_epochs:\n",
    "            model.eval()\n",
    "            y_true, y_pred_probs = [], []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in test_loader:\n",
    "                    out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "                    y_true.extend(batch.y.cpu().numpy())\n",
    "                    y_pred_probs.extend(out.cpu().numpy())\n",
    "\n",
    "            y_pred_probs = np.array(y_pred_probs).flatten()\n",
    "            auc_score = roc_auc_score(y_true, y_pred_probs)\n",
    "\n",
    "            if auc_score > best_auc:\n",
    "                best_params = params\n",
    "                best_auc = auc_score\n",
    "            print(f\"Epoch \n",
    "                  {epoch}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | AUC: {auc_score:.4f} | Time: {epoch_duration:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'batch_size': 4096, 'heads': 16, 'hidden_dim': 16, 'lr': 0.0001, 'num_neighbors': [64, 64]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"batch_size\": 512, \"num_neighbors\":[256, 256]}\n",
    "heads=32\n",
    "hidden_dim=32\n",
    "lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_loader(graph_data, graph_data.train_mask, params)\n",
    "test_loader = create_loader(graph_data, graph_data.val_mask, params)\n",
    "\n",
    "model = GATModel(\n",
    "    in_feats=graph_data.num_features,\n",
    "    hidden_dim=hidden_dim,\n",
    "    out_feats=1,\n",
    "    heads=heads\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0 \n",
    "    \n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        loss = criterion(out, batch.y.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    epoch_duration = time.time() - start_time\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == num_epochs:\n",
    "        model.eval()\n",
    "        y_true, y_pred_probs = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "                y_true.extend(batch.y.cpu().numpy())\n",
    "                y_pred_probs.extend(out.cpu().numpy())\n",
    "\n",
    "        y_pred_probs = np.array(y_pred_probs).flatten()\n",
    "        auc_score = roc_auc_score(y_true, y_pred_probs)\n",
    "        print(f\"Epoch \n",
    "                {epoch}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | AUC: {auc_score:.4f} | Time: {epoch_duration:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred_probs):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='grey', linestyle='--')  # Linha aleatória\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
    "    plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
    "    plt.title('Curva ROC')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_true, y_pred_probs = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        y_true.extend(batch.y.cpu().numpy())\n",
    "        y_pred_probs.extend(out.cpu().numpy())\n",
    "\n",
    "y_pred_probs = np.array(y_pred_probs).flatten()\n",
    "#y_pred = (y_pred_probs >= 0.1).astype(int)  # Converter para 0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(y_true, y_pred_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
