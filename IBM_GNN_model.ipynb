{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "from typing import Callable, Optional\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch_geometric.data import (\n",
    "    Data,\n",
    "    InMemoryDataset\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "path = './src/data/HI-Small_Trans.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>From Bank</th>\n",
       "      <th>Account</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Account.1</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Receiving Currency</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>Payment Currency</th>\n",
       "      <th>Payment Format</th>\n",
       "      <th>Is Laundering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022/09/01 00:20</td>\n",
       "      <td>10</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>10</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>3697.34</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>3697.34</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022/09/01 00:20</td>\n",
       "      <td>3208</td>\n",
       "      <td>8000F4580</td>\n",
       "      <td>1</td>\n",
       "      <td>8000F5340</td>\n",
       "      <td>0.01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>0.01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022/09/01 00:00</td>\n",
       "      <td>3209</td>\n",
       "      <td>8000F4670</td>\n",
       "      <td>3209</td>\n",
       "      <td>8000F4670</td>\n",
       "      <td>14675.57</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>14675.57</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022/09/01 00:02</td>\n",
       "      <td>12</td>\n",
       "      <td>8000F5030</td>\n",
       "      <td>12</td>\n",
       "      <td>8000F5030</td>\n",
       "      <td>2806.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>2806.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022/09/01 00:06</td>\n",
       "      <td>10</td>\n",
       "      <td>8000F5200</td>\n",
       "      <td>10</td>\n",
       "      <td>8000F5200</td>\n",
       "      <td>36682.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>36682.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
       "0  2022/09/01 00:20         10  8000EBD30       10  8000EBD30   \n",
       "1  2022/09/01 00:20       3208  8000F4580        1  8000F5340   \n",
       "2  2022/09/01 00:00       3209  8000F4670     3209  8000F4670   \n",
       "3  2022/09/01 00:02         12  8000F5030       12  8000F5030   \n",
       "4  2022/09/01 00:06         10  8000F5200       10  8000F5200   \n",
       "\n",
       "   Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
       "0          3697.34          US Dollar      3697.34        US Dollar   \n",
       "1             0.01          US Dollar         0.01        US Dollar   \n",
       "2         14675.57          US Dollar     14675.57        US Dollar   \n",
       "3          2806.97          US Dollar      2806.97        US Dollar   \n",
       "4         36682.97          US Dollar     36682.97        US Dollar   \n",
       "\n",
       "  Payment Format  Is Laundering  \n",
       "0   Reinvestment              0  \n",
       "1         Cheque              0  \n",
       "2   Reinvestment              0  \n",
       "3   Reinvestment              0  \n",
       "4   Reinvestment              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5078345, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_label_encoder(df, columns):\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        for i in columns:\n",
    "            df[i] = le.fit_transform(df[i].astype(str))\n",
    "        return df\n",
    "\n",
    "def preprocess(df):\n",
    "        df = df_label_encoder(df,['Payment Format', 'Payment Currency', 'Receiving Currency'])\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "        df['Timestamp'] = df['Timestamp'].apply(lambda x: x.value)\n",
    "        df['Timestamp'] = (df['Timestamp']-df['Timestamp'].min())/(df['Timestamp'].max()-df['Timestamp'].min())\n",
    "\n",
    "        df['Account'] = df['From Bank'].astype(str) + '_' + df['Account']\n",
    "        df['Account.1'] = df['To Bank'].astype(str) + '_' + df['Account.1']\n",
    "        df = df.sort_values(by=['Account'])\n",
    "        receiving_df = df[['Account.1', 'Amount Received', 'Receiving Currency']]\n",
    "        paying_df = df[['Account', 'Amount Paid', 'Payment Currency']]\n",
    "        receiving_df = receiving_df.rename({'Account.1': 'Account'}, axis=1)\n",
    "        currency_ls = sorted(df['Receiving Currency'].unique())\n",
    "\n",
    "        return df, receiving_df, paying_df, currency_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, receiving_df, paying_df, currency_ls = preprocess(df = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_account(df):\n",
    "    ldf = df[['Account', 'From Bank']]\n",
    "    rdf = df[['Account.1', 'To Bank']]\n",
    "    suspicious = df[df['Is Laundering']==1]\n",
    "    s1 = suspicious[['Account', 'Is Laundering']]\n",
    "    s2 = suspicious[['Account.1', 'Is Laundering']]\n",
    "    s2 = s2.rename({'Account.1': 'Account'}, axis=1)\n",
    "    suspicious = pd.concat([s1, s2], join='outer')\n",
    "    suspicious = suspicious.drop_duplicates()\n",
    "\n",
    "    ldf = ldf.rename({'From Bank': 'Bank'}, axis=1)\n",
    "    rdf = rdf.rename({'Account.1': 'Account', 'To Bank': 'Bank'}, axis=1)\n",
    "    df = pd.concat([ldf, rdf], join='outer')\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    df['Is Laundering'] = 0\n",
    "    df.set_index('Account', inplace=True)\n",
    "    df.update(suspicious.set_index('Account'))\n",
    "    df = df.reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts = get_all_account(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paid_currency_aggregate(currency_ls, paying_df, accounts):\n",
    "        for i in currency_ls:\n",
    "            temp = paying_df[paying_df['Payment Currency'] == i]\n",
    "            accounts['avg paid '+str(i)] = temp['Amount Paid'].groupby(temp['Account']).transform('mean')\n",
    "        return accounts\n",
    "\n",
    "def received_currency_aggregate(currency_ls, receiving_df, accounts):\n",
    "    for i in currency_ls:\n",
    "        temp = receiving_df[receiving_df['Receiving Currency'] == i]\n",
    "        accounts['avg received '+str(i)] = temp['Amount Received'].groupby(temp['Account']).transform('mean')\n",
    "    accounts = accounts.fillna(0)\n",
    "    return accounts\n",
    "\n",
    "def get_node_attr(currency_ls, paying_df, receiving_df, accounts):\n",
    "    node_df = paid_currency_aggregate(currency_ls, paying_df, accounts)\n",
    "    #node_df = received_currency_aggregate(currency_ls, receiving_df, node_df)\n",
    "    node_label = torch.from_numpy(node_df['Is Laundering'].values).to(torch.float)\n",
    "    #node_df = node_df.drop(['Account', 'Is Laundering'], axis=1)\n",
    "    #node_df = df_label_encoder(node_df,['Bank'])\n",
    "    #node_df = torch.from_numpy(node_df.values).to(torch.float)\n",
    "    return node_df, node_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account</th>\n",
       "      <th>Bank</th>\n",
       "      <th>Is Laundering</th>\n",
       "      <th>avg paid 0</th>\n",
       "      <th>avg paid 1</th>\n",
       "      <th>avg paid 2</th>\n",
       "      <th>avg paid 3</th>\n",
       "      <th>avg paid 4</th>\n",
       "      <th>avg paid 5</th>\n",
       "      <th>avg paid 6</th>\n",
       "      <th>avg paid 7</th>\n",
       "      <th>avg paid 8</th>\n",
       "      <th>avg paid 9</th>\n",
       "      <th>avg paid 10</th>\n",
       "      <th>avg paid 11</th>\n",
       "      <th>avg paid 12</th>\n",
       "      <th>avg paid 13</th>\n",
       "      <th>avg paid 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10057_803A115E0</td>\n",
       "      <td>10057</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1922.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10057_803AA8E90</td>\n",
       "      <td>10057</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>480.223333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10057_803AAB430</td>\n",
       "      <td>10057</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14675.570000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10057_803AACE20</td>\n",
       "      <td>10057</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37340.843333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10057_803AB4F70</td>\n",
       "      <td>10057</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49649.409677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Account   Bank  Is Laundering  avg paid 0  avg paid 1  avg paid 2  \\\n",
       "0  10057_803A115E0  10057              0         NaN         NaN         NaN   \n",
       "1  10057_803AA8E90  10057              0         NaN         NaN         NaN   \n",
       "2  10057_803AAB430  10057              0         NaN         NaN         NaN   \n",
       "3  10057_803AACE20  10057              0         NaN         NaN         NaN   \n",
       "4  10057_803AB4F70  10057              0         NaN         NaN         NaN   \n",
       "\n",
       "   avg paid 3  avg paid 4  avg paid 5  avg paid 6  avg paid 7  avg paid 8  \\\n",
       "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "   avg paid 9  avg paid 10  avg paid 11   avg paid 12  avg paid 13  \\\n",
       "0         NaN          NaN          NaN   1922.000000          NaN   \n",
       "1         NaN          NaN          NaN    480.223333          NaN   \n",
       "2         NaN          NaN          NaN  14675.570000          NaN   \n",
       "3         NaN          NaN          NaN  37340.843333          NaN   \n",
       "4         NaN          NaN          NaN  49649.409677          NaN   \n",
       "\n",
       "   avg paid 14  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_df, node_label = get_node_attr(currency_ls, paying_df,receiving_df, accounts)\n",
    "node_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GATConv, Linear\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads, dropout=0.6)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, int(hidden_channels/4), heads=1, concat=False, dropout=0.6)\n",
    "        self.lin = Linear(int(hidden_channels/4), out_channels)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index, edge_attr))\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.elu(self.conv2(x, edge_index, edge_attr))\n",
    "        x = self.lin(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMLtoGraph(InMemoryDataset):\n",
    "\n",
    "    def __init__(self, root: str, edge_window_size: int = 10,\n",
    "                 transform: Optional[Callable] = None,\n",
    "                 pre_transform: Optional[Callable] = None):\n",
    "        self.edge_window_size = edge_window_size\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> str:\n",
    "        return 'HI-Small_Trans.csv'\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return 'data.pt'\n",
    "\n",
    "    @property\n",
    "    def num_nodes(self) -> int:\n",
    "        return self._data.edge_index.max().item() + 1\n",
    "\n",
    "    def df_label_encoder(self, df, columns):\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        for i in columns:\n",
    "            df[i] = le.fit_transform(df[i].astype(str))\n",
    "        return df\n",
    "\n",
    "\n",
    "    def preprocess(self, df):\n",
    "        df = self.df_label_encoder(df,['Payment Format', 'Payment Currency', 'Receiving Currency'])\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "        df['Timestamp'] = df['Timestamp'].apply(lambda x: x.value)\n",
    "        df['Timestamp'] = (df['Timestamp']-df['Timestamp'].min())/(df['Timestamp'].max()-df['Timestamp'].min())\n",
    "\n",
    "        df['Account'] = df['From Bank'].astype(str) + '_' + df['Account']\n",
    "        df['Account.1'] = df['To Bank'].astype(str) + '_' + df['Account.1']\n",
    "        df = df.sort_values(by=['Account'])\n",
    "        receiving_df = df[['Account.1', 'Amount Received', 'Receiving Currency']]\n",
    "        paying_df = df[['Account', 'Amount Paid', 'Payment Currency']]\n",
    "        receiving_df = receiving_df.rename({'Account.1': 'Account'}, axis=1)\n",
    "        currency_ls = sorted(df['Receiving Currency'].unique())\n",
    "\n",
    "        return df, receiving_df, paying_df, currency_ls\n",
    "\n",
    "    def get_all_account(self, df):\n",
    "        ldf = df[['Account', 'From Bank']]\n",
    "        rdf = df[['Account.1', 'To Bank']]\n",
    "        suspicious = df[df['Is Laundering']==1]\n",
    "        s1 = suspicious[['Account', 'Is Laundering']]\n",
    "        s2 = suspicious[['Account.1', 'Is Laundering']]\n",
    "        s2 = s2.rename({'Account.1': 'Account'}, axis=1)\n",
    "        suspicious = pd.concat([s1, s2], join='outer')\n",
    "        suspicious = suspicious.drop_duplicates()\n",
    "\n",
    "        ldf = ldf.rename({'From Bank': 'Bank'}, axis=1)\n",
    "        rdf = rdf.rename({'Account.1': 'Account', 'To Bank': 'Bank'}, axis=1)\n",
    "        df = pd.concat([ldf, rdf], join='outer')\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        df['Is Laundering'] = 0\n",
    "        df.set_index('Account', inplace=True)\n",
    "        df.update(suspicious.set_index('Account'))\n",
    "        df = df.reset_index()\n",
    "        return df\n",
    "    \n",
    "    def paid_currency_aggregate(self, currency_ls, paying_df, accounts):\n",
    "        for i in currency_ls:\n",
    "            temp = paying_df[paying_df['Payment Currency'] == i]\n",
    "            accounts['avg paid '+str(i)] = temp['Amount Paid'].groupby(temp['Account']).transform('mean')\n",
    "        return accounts\n",
    "\n",
    "    def received_currency_aggregate(self, currency_ls, receiving_df, accounts):\n",
    "        for i in currency_ls:\n",
    "            temp = receiving_df[receiving_df['Receiving Currency'] == i]\n",
    "            accounts['avg received '+str(i)] = temp['Amount Received'].groupby(temp['Account']).transform('mean')\n",
    "        accounts = accounts.fillna(0)\n",
    "        return accounts\n",
    "\n",
    "    def get_edge_df(self, accounts, df):\n",
    "        accounts = accounts.reset_index(drop=True)\n",
    "        accounts['ID'] = accounts.index\n",
    "        mapping_dict = dict(zip(accounts['Account'], accounts['ID']))\n",
    "        df['From'] = df['Account'].map(mapping_dict)\n",
    "        df['To'] = df['Account.1'].map(mapping_dict)\n",
    "        df = df.drop(['Account', 'Account.1', 'From Bank', 'To Bank'], axis=1)\n",
    "\n",
    "        edge_index = torch.stack([torch.from_numpy(df['From'].values), torch.from_numpy(df['To'].values)], dim=0)\n",
    "\n",
    "        df = df.drop(['Is Laundering', 'From', 'To'], axis=1)\n",
    "\n",
    "        edge_attr = torch.from_numpy(df.values).to(torch.float)\n",
    "        return edge_attr, edge_index\n",
    "\n",
    "    def get_node_attr(self, currency_ls, paying_df,receiving_df, accounts):\n",
    "        node_df = self.paid_currency_aggregate(currency_ls, paying_df, accounts)\n",
    "        node_df = self.received_currency_aggregate(currency_ls, receiving_df, node_df)\n",
    "        node_label = torch.from_numpy(node_df['Is Laundering'].values).to(torch.float)\n",
    "        node_df = node_df.drop(['Account', 'Is Laundering'], axis=1)\n",
    "        node_df = self.df_label_encoder(node_df,['Bank'])\n",
    "        node_df = torch.from_numpy(node_df.values).to(torch.float)\n",
    "        return node_df, node_label\n",
    "\n",
    "    def process(self):\n",
    "        df = pd.read_csv(self.raw_paths[0])\n",
    "        df, receiving_df, paying_df, currency_ls = self.preprocess(df)\n",
    "        accounts = self.get_all_account(df)\n",
    "        node_attr, node_label = self.get_node_attr(currency_ls, paying_df,receiving_df, accounts)\n",
    "        edge_attr, edge_index = self.get_edge_df(accounts, df)\n",
    "\n",
    "        data = Data(x=node_attr,\n",
    "                    edge_index=edge_index,\n",
    "                    y=node_label,\n",
    "                    edge_attr=edge_attr\n",
    "                    )\n",
    "        \n",
    "        data_list = [data] \n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [d for d in data_list if self.pre_filter(d)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(d) for d in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred_probs):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='grey', linestyle='--')  # Linha aleatória\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
    "    plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
    "    plt.title('Curva ROC')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset = AMLtoGraph(\"./src/data/\")\n",
    "data = dataset[0]\n",
    "epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GAT(in_channels=data.num_features, hidden_channels=16, out_channels=1, heads=8)\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "split = T.RandomNodeSplit(split='train_rest', num_val=0.1, num_test=0)\n",
    "data = split(data)\n",
    "\n",
    "train_loader = loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[30] * 2,\n",
    "    batch_size=256,\n",
    "    input_nodes=data.train_mask,\n",
    ")\n",
    "\n",
    "test_loader = loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[30] * 2,\n",
    "    batch_size=256,\n",
    "    input_nodes=data.val_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epoch):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        data.to(device)\n",
    "        pred = model(data.x, data.edge_index, data.edge_attr)\n",
    "        ground_truth = data.y\n",
    "        loss = criterion(pred, ground_truth.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss)\n",
    "    if epoch%10 == 0:\n",
    "        print(f\"Epoch: {i:03d}, Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_true, y_pred_probs = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch.to(device)\n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        y_true.extend(batch.y.cpu().numpy())\n",
    "        y_pred_probs.extend(out.cpu().numpy())\n",
    "\n",
    "y_pred_probs = np.array(y_pred_probs).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(y_true, y_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Não Lavador', 'Lavador'], yticklabels=['Não Lavador', 'Lavador'])\n",
    "    plt.xlabel('Previsão')\n",
    "    plt.ylabel('Real')\n",
    "    plt.title('Matriz de Confusão')\n",
    "    plt.show()\n",
    "\n",
    "y_pred = (y_pred_probs >= 1e-40).astype(int)\n",
    "\n",
    "plot_confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
