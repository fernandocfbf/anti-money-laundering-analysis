{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#external\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "#sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score \n",
    "from sklearn.metrics import recall_score, confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "\n",
    "#models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "#utils\n",
    "from src.utils.dataset import get_full_transactions_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_full_transactions_dataset().sample(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.is_laundering.value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranformations\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_transformations(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    dataframe = dataframe.drop(columns=[\"sender\", \"receiver\"])\n",
    "    dataframe[\"timestamp\"] = pd.to_datetime(dataframe[\"timestamp\"])\n",
    "    dataframe[\"timestamp\"] = dataframe[\"timestamp\"].apply(lambda timestamp_value: timestamp_value.value)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = custom_transformations(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining pipeline\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"is_laundering\"])\n",
    "y = df[\"is_laundering\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = X.select_dtypes(include=\"object\").columns\n",
    "numerical_columns = X.select_dtypes(exclude=\"object\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline = Pipeline([\n",
    "    (\"scaler\", RobustScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"encoder\", OrdinalEncoder())\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"numerical_pipeline\", numerical_pipeline, numerical_columns),\n",
    "    (\"categorical_pipeline\", categorical_pipeline, categorical_columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(True), y_test.value_counts(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess.fit_transform(X_train)\n",
    "X_test = preprocess.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(random_state=42, sampling_strategy=0.25)\n",
    "X_train_resample, y_train_resample = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_resample.value_counts(), y_test.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parameter = {\n",
    "    \"n_estimators\": [100, 300, 500],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"min_child_weight\": [1, 3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_boost_grid = GridSearchCV(\n",
    "    estimator=XGBClassifier(device=\"cuda\", random_state=42),\n",
    "    param_grid=grid_parameter,\n",
    "    cv=3,\n",
    "    scoring=\"f1\", \n",
    "    verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_boost_model = xg_boost_grid.fit(X_train_resample, y_train_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best parameters: {xg_boost_model.best_params_}\")\n",
    "print(f\"Best score is: {xg_boost_model.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parameter = {\n",
    "    \"max_depth\": [4, 8, 16],\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_features\": [20, 40, 80]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_grid = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=grid_parameter,\n",
    "    cv=3,\n",
    "    scoring=\"roc_auc\", \n",
    "    verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = random_forest_grid.fit(X_train_resample, y_train_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best parameters: {random_forest_model.best_params_}\")\n",
    "print(f\"Best score is: {random_forest_model.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing best model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataframe = get_full_transactions_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_transactions_df = full_dataframe[full_dataframe[\"is_laundering\"] == 1]\n",
    "non_fraud_transactions_df = full_dataframe[full_dataframe[\"is_laundering\"] == 0].sample(int(100e3))\n",
    "sample_dataframe = pd.concat([fraud_transactions_df, non_fraud_transactions_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataframe.is_laundering.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataframe.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataframe = custom_transformations(sample_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_dataframe.drop(columns=[\"is_laundering\"])\n",
    "y = sample_dataframe[\"is_laundering\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = ImbPipeline([\n",
    "    (\"preprocess\", preprocess), \n",
    "    (\"smote\", SMOTE(random_state=42, sampling_strategy=0.25)),\n",
    "    (\"model\", XGBClassifier(learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=500, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=8, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_result = cross_validate(\n",
    "    full_pipeline,\n",
    "    X,\n",
    "    y,\n",
    "    cv=cv,\n",
    "    scoring=(\"f1\", \"accuracy\", \"roc_auc\"),\n",
    "    verbose=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cross_val_predict(full_pipeline, X, y, cv=cv)\n",
    "y_pred_prob = cross_val_predict(full_pipeline, X, y, cv=cv, method='predict_proba')[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y, y_pred)\n",
    "print(f'Accuracy: {acc:.4f}')\n",
    "\n",
    "f1 = f1_score(y, y_pred)  \n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "precision = precision_score(y, y_pred)\n",
    "print(f'Precision: {precision:.4f}')\n",
    "\n",
    "recall = recall_score(y, y_pred)\n",
    "print(f'Recall: {recall:.4f}')\n",
    "\n",
    "auc_score = roc_auc_score(y, y_pred_prob)\n",
    "print(f'AUC: {auc_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'], cbar=False)\n",
    "plt.title('Confusion matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Real')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkblue', lw=2, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.sqrt(fpr**2 + (1 - tpr)**2)\n",
    "best_threshold_idx = np.argmin(distances)\n",
    "best_threshold = thresholds[best_threshold_idx]\n",
    "print(f'O melhor limiar (threshold) Ã© {best_threshold:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_adjusted = (y_pred_prob >= best_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y, y_pred_adjusted)\n",
    "print(f'Accuracy: {acc:.4f}')\n",
    "\n",
    "f1 = f1_score(y, y_pred_adjusted)  \n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "precision = precision_score(y, y_pred_adjusted)\n",
    "print(f'Precision: {precision:.4f}')\n",
    "\n",
    "recall = recall_score(y, y_pred_adjusted)\n",
    "print(f'Recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y, y_pred_adjusted)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'], cbar=False)\n",
    "plt.title('Confusion matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Real')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(full_pipeline, \"xgb_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making prediction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 18:51:57.115 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-06 18:51:57.117 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-06 18:51:57.118 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-06 18:51:57.633 Thread 'Thread-35': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-06 18:51:57.637 Thread 'Thread-35': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-06 18:52:04.535 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-06 18:52:04.536 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "df = get_full_transactions_dataset(account_id=\"1024_800ECB1A0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_transformations(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    dataframe = dataframe.drop(columns=[\"sender\", \"receiver\", \"is_laundering\"])\n",
    "    dataframe[\"timestamp\"] = pd.to_datetime(dataframe[\"timestamp\"])\n",
    "    dataframe[\"timestamp\"] = dataframe[\"timestamp\"].apply(lambda timestamp_value: timestamp_value.value)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = custom_transformations(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pipeline = joblib.load(\"xgb_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loaded_pipeline.predict(X)\n",
    "y_proba = loaded_pipeline.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999966"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba[np.argmax(y_proba)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.9203364e-06, 6.9044542e-04, 2.6671486e-03, ..., 7.1519884e-05,\n",
       "        3.3266802e-04, 1.4664488e-02], dtype=float32),\n",
       " array([0, 0, 0, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
